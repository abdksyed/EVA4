{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 Handwritten Number Detection using PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMB8Pl1S7GELbNt7oPwplSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abksyed/02MNIST/blob/master/01%20Handwritten%20Number%20Detection%20using%20PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Nh_8EwdbMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8y3iIEe59v-",
        "colab_type": "text"
      },
      "source": [
        "**Creating Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH67EEGldsNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__() # Inheriting __init__ method from  nn.Module Class\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding= 1) #Creating Conv2d Method, with 1 channels in input image (28 x 28 x 1 - before padding), \n",
        "                                                  #and giving 32 channels in the output using 32 kernels of size 3 x 3 x 1 and padding of 1. Receptive Field of 3\n",
        "    \n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding= 1) #Creating Conv2d Method, with 32 channels in input image (28 x 28 x 32 - before padding), \n",
        "                                                  #and giving 64 channels in the output using 64 kernels of size 3 x 3 x 1 and padding of 1. Receptive Field of 5\n",
        "    \n",
        "    self.pool1 = nn.MaxPool2d(2,2) #Creating a MaxPool2d Method, with kernel of 2 and stride 2, taking an input of (28 x 28 x 64) giving an output of (14 X 14 X 64). Receptive Field of 10\n",
        "    \n",
        "    self.conv3 = nn.Conv2d(64, 128, 3, padding= 1) #Creating Conv2d Method, with 64 channels in input image (14 x 14 x 64 - before padding), \n",
        "                                                    #and giving 128 channels in the output using 128 kernels of size 3 x 3 x 1 and padding of 1. Receptive Field of 12\n",
        "    \n",
        "    self.conv4 = nn.Conv2d(128, 256, 3, padding= 1) #Creating Conv2d Method, with 128 channels in input image (14 x 14 x 128 - before padding), \n",
        "                                                    #and giving 256 channels in the output using 256 kernels of size 3 x 3 x 1 and padding of 1. Receptive Field of 14.\n",
        "    \n",
        "    self.pool2 = nn.MaxPool2d(2,2) #Creating a MaxPool2d Method, with kernel of 2 and stride 2, taking an input of (14 x 14 x 256) giving an output of (7 X 7 X 256). Receptive Field of 28\n",
        "    \n",
        "    self.conv5 = nn.Conv2d(256, 512, 3) #Creating Conv2d Method, with 256 channels in input image (7 x 7 x 256), \n",
        "                                                    #and giving 512 channels in the output (5 x 5 x 512) using 512 kernels of size 3 x 3 x 1. Receptive Field of 30.\n",
        "    \n",
        "    self.conv6 = nn.Conv2d(512, 1024, 3) #Creating Conv2d Method, with 512 channels in input image (5 x 5 x 512), \n",
        "                                                    #and giving 1024 channels in the output (3 x 3 x 1024) using 1024 kernels of size 3 x 3 x 1. Receptive Field of 32.                                                \n",
        "    \n",
        "    self.conv7 = nn.Conv2d(1024, 10, 3) #Creating Conv2d Method, with 256 channels in input image (3 x 3 x 1024), \n",
        "                                                    #and giving 10 channels in the output (1 x 1 x 10) using 10 kernels of size 3 x 3 x 1. Receptive Field of 34\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "    x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "    x = F.relu(self.conv7(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "\n",
        "    x = x.view(-1, 10)\n",
        "    \n",
        "    return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhhx4yuU6HMO",
        "colab_type": "text"
      },
      "source": [
        "**Initantiating Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObF_2yHz6NLy",
        "colab_type": "code",
        "outputId": "538e5558-540a-4f17-e69c-4d2a0dc47b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtKV9A608BIw",
        "colab_type": "text"
      },
      "source": [
        "**Creating Batch and Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Du5W_iD60yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch = 128 #Creating each batch of 128 images.\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} #Creating Key word arguments to be used when CUDA is available.\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train= True, download= True, \n",
        "                   transform= transforms.Compose([\n",
        "                                                  transforms.ToTensor(), #Converting it to Tensor\n",
        "                                                  transforms.Normalize((0.1307,), (0.3081,)) #Normalize((a,b,c)mean, (p,q,r)std dev) for 3 channels mean and std dev a,p ; b,q and c,r respectively.\n",
        "                   ]                    \n",
        "                   )),\n",
        "    batch_size = batch, shuffle= True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train= False,\n",
        "                  transform= transforms.Compose([\n",
        "                                                 transforms.ToTensor(),\n",
        "                                                 transforms.Normalize((0.1307,), (0.3081,))\n",
        "                  ])),\n",
        "    batch_size = batch, shuffle= True, **kwargs\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtAXaGvwonuY",
        "colab_type": "text"
      },
      "source": [
        "**Training the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4elBoycvTjI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_values = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob56Zk7aoPJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train() #Setting the model in Training mode.\n",
        "  pbar = tqdm(train_loader) #Wrapping iterable in tqdm shows the progess bar of the iterable when looping\n",
        "\n",
        "  for batch_idx, (data,target) in enumerate(pbar):\n",
        "    data, target = data.to(device), target.to(device) #Converting the variables to work on GPU.\n",
        "    optimizer.zero_grad() #Clearing all the gradients from the previous run for the new batch.\n",
        "    output = model(data) #Finding the output.\n",
        "    loss = F.nll_loss(output, target) #Calculating Loss.\n",
        "    loss.backward() #Backpropogation\n",
        "    optimizer.step()\n",
        "    pbar.set_description(desc= f'loss= {loss.item()} batch_id = {batch_idx}') #Giving description to the progess bar\n",
        "\n",
        "def test(model, device, test_loader):\n",
        " model.eval() #Setting the model to Eval or Testing Mode.\n",
        " test_loss = 0\n",
        " correct = 0\n",
        " with torch.no_grad(): #Asking not to use gradients, to reduce memory usage as Gradients are not needed when evaluation.\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    test_loss += F.nll_loss(output, target, reduction= 'sum').item() #Sum up the batch loss\n",
        "    pred = output.argmax(dim= 1, keepdim= True) #get the index of max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('\\nTest Set: Average Loss: {:4f}, Accuracy {}/{} ){:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)\n",
        "      ))\n",
        "  loss_values.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcau9IEbeWx9",
        "colab_type": "code",
        "outputId": "48555729-316d-4642-9e0a-c2769c5047fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "model = Net().to(device) #Intantiating a class\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr= 0.01, momentum= 0.9)\n",
        "\n",
        "for epoch in range(1,10):\n",
        "  train(model, device, train_loader, optimizer, epoch)\n",
        "  test(model, device, test_loader)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss= 1.794254183769226 batch_id = 468: 100%|██████████| 469/469 [00:37<00:00, 12.49it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 1.726100, Accuracy 3786/10000 )38%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.8433466553688049 batch_id = 468: 100%|██████████| 469/469 [00:37<00:00, 12.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.835172, Accuracy 6936/10000 )69%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.8340342044830322 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.20it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.734237, Accuracy 7863/10000 )79%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.45358455181121826 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.30it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.500805, Accuracy 8862/10000 )89%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.43458905816078186 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.30it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.494560, Accuracy 8905/10000 )89%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.5092942118644714 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.32it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.497683, Accuracy 8907/10000 )89%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.5324965119361877 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.30it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.492099, Accuracy 8920/10000 )89%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.43828654289245605 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.32it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.495550, Accuracy 8909/10000 )89%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss= 0.4560554027557373 batch_id = 468: 100%|██████████| 469/469 [00:38<00:00, 12.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set: Average Loss: 0.492811, Accuracy 8912/10000 )89%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6Pl6E9Bkzjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1f272b2b-031a-4321-cf13-e4b2fa23833a"
      },
      "source": [
        "plt.plot(loss_values)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa760a39588>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncNZD8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEzau3wB2Pk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}